# User Engagement Analytics

Epsilla provides a comprehensive analytics platform for monitoring user engagement and feedback related to AI agents. This allows users to track key metrics that reflect the performance and effectiveness of the agents in serving their intended tasks. The platform includes various analytic tools and dashboards to offer detailed insights, which are vital for continuous agent optimization and improvement.

Switch to the **Analyze** tab of an AI agent to access the analytics.

<figure><img src="../.gitbook/assets/Screenshot 2024-10-14 at 1.01.06 AM.png" alt=""><figcaption></figcaption></figure>

The platform allows users to filter data across different time ranges (e.g., last 3 days, last 7 days, last 30 days, and last 90 days). This helps AI agent builders analyze trends over both short and long periods, providing a more nuanced understanding of performance dynamics.

<figure><img src="../.gitbook/assets/Screenshot 2024-10-14 at 1.02.10 AM.png" alt="" width="107"><figcaption></figcaption></figure>

### **The Metrics**

<figure><img src="../.gitbook/assets/Screenshot 2024-10-14 at 1.08.33 AM.png" alt="" width="563"><figcaption></figcaption></figure>

**Daily/Weekly Active Users**

This chart tracks how many unique users interacted with the AI agent on a daily/weekly basis. Monitoring active users allows agent builder to gauge the ongoing demand for the agent's assistance, ensuring it remains relevant and useful for users.

**Daily/Weekly User Asked Questions**

This chart displays the number of questions posed to the AI agent daily/weekly. It serves as a proxy for user engagement and interaction depth.

**Total Feedback**

The platform uses a pie chart to show the proportion of positive vs. negative feedback received across all interactions during the time period. Feedback allows users to measure satisfaction with the AI agent’s responses, which can be crucial in assessing the quality of its performance.

**Daily/Weekly Feedback**

Weekly feedback charts help monitor sentiment over time, which provides insights into how the AI agent’s performance evolves. Negative feedback in particular highlights areas where users are dissatisfied and prompts immediate action.

### **User Engagement History**

The detailed conversation or search logs provide the history of each interaction with the AI agent. For example, a conversation where the user asked a chatbot, or a search question where the user asked a smart search app. It also traces feedback back to those interactions, offering valuable context for understanding why users rated the interaction positively or negatively.

Click the interaction from the table to drill down the user interaction in depth:

<figure><img src="../.gitbook/assets/Screenshot 2024-10-14 at 1.01.50 AM.png" alt=""><figcaption></figcaption></figure>

<figure><img src="../.gitbook/assets/Screenshot 2024-10-14 at 1.02.02 AM.png" alt=""><figcaption></figcaption></figure>

Click the **Back to Preview** button in the bottom right corner to return to the Preview.

### Improvement Based on User Feedback

By using the detailed feedback available through the platform, you as the AI agent builder can go back to **Edit** and fine-tune the agent configuration, continuously improving them to meet the evolving needs of your users.
